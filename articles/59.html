<!DOCTYPE html><html><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width"/><title>卡鲁秋 - 前端小工具</title><link rel="icon" href="/frontend/favicon.ico"/><meta name="description" content="卡鲁秋的前端工具网站，提供了一系列实用的前端开发工具和功能，技术网站汇总，旨在帮助开发者更加高效地进行前端开发。"/><meta name="keywords" content="前端工具,前端开发,前端开发工具,前端开发工具集合,toolbox,frontend,卡鲁秋,Hank,HankLiu"/><meta name="author" content="Hank.Liu"/><meta name="next-head-count" content="7"/><link rel="stylesheet" href="/frontend/styles/animate.css/@4.1.1/animate.css"/><link rel="preload" href="/frontend/_next/static/css/f5460a021fc371e8.css" as="style"/><link rel="stylesheet" href="/frontend/_next/static/css/f5460a021fc371e8.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/frontend/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js"></script><script src="/frontend/_next/static/chunks/webpack-1bf31be8095fc118.js" defer=""></script><script src="/frontend/_next/static/chunks/framework-aec4381329cec0e4.js" defer=""></script><script src="/frontend/_next/static/chunks/main-899fdecfa3f91f4c.js" defer=""></script><script src="/frontend/_next/static/chunks/pages/_app-f9f0bae13d326327.js" defer=""></script><script src="/frontend/_next/static/chunks/9691-52831ba1a45a37ee.js" defer=""></script><script src="/frontend/_next/static/chunks/8490-9c9cad1e305c687c.js" defer=""></script><script src="/frontend/_next/static/chunks/1664-f865873e77459860.js" defer=""></script><script src="/frontend/_next/static/chunks/pages/articles/%5Bid%5D-b6bd1d5b4743d958.js" defer=""></script><script src="/frontend/_next/static/0KgTm-4rBEt_lvVIgTS_U/_buildManifest.js" defer=""></script><script src="/frontend/_next/static/0KgTm-4rBEt_lvVIgTS_U/_ssgManifest.js" defer=""></script></head><body><div id="__next"><div class="flex h-full min-h-[100vh] w-full flex-col" style="flex-direction:column;min-height:100vh"><main class="flex flex-1 grow-[1] flex-col" style="flex:1"><div class="flex h-full flex-1 flex-col" style="position:relative"><div class="flex space-x-6 bg-white p-6"><div class="flex-1 overflow-x-hidden"><div class="ant-card ant-card-bordered article-card min-h-full !border-[#d9d9d9] css-12jzuas"><div class="ant-card-body"><article><div class="mx-auto mb-[36px] max-w-[1045px] px-[30px] lg:mb-[52px] lg:flex lg:px-0"><div id="banner" class="media-wrapper image-media-wrapper w-full overflow-hidden rounded-[8px] border-[1px] border-solid border-[#1D2129] lg:ml-0 lg:h-[320px] lg:w-[500px]"><div class="hidden before"></div><div class="hidden after"></div><div class="scale-103 h-full w-full border-[8px] border-solid border-white lg:scale-100 cover-wrapper"><img class="h-full w-full rounded-md object-cover cover" src="/frontend/dashboard/images/banner.png" alt=""/></div></div><div class="mt-[60px] overflow-hidden lg:ml-[32px] lg:mt-0 lg:flex-1"><h1 class="leading-130 montserrat-bold mb-[9px] text-[36px] font-medium text-[#1D2129] lg:mb-[8px]">浏览器中的WebRTC音视频通讯</h1><div class="mb-[9px] flex whitespace-nowrap lg:mb-[10px]"><div class="leading-120 cursor-pointer truncate text-[24px] font-normal text-[#1D2129] underline-offset-2 hover:underline lg:text-[20px]" aria-hidden="true"># VOL.<!-- -->59</div><div class="leading-120 ml-[48px] text-[24px] font-normal text-[#1D2129] lg:ml-[32px] lg:text-[20px]">2021/12/31</div></div><div class="mb-[12px] flex flex-wrap lg:mb-0"><div class="leading-150 mb-[12px] mr-[18px] rounded-[30px] border border-solid border-[#1D2129] px-[24px] py-[6px] text-[20px] font-normal text-[#1D2129] lg:mb-[12px] lg:mr-[10px] lg:rounded-[20px] lg:px-[16px] lg:py-[4px] lg:text-[14px]">blog</div></div><div class="my-[30px] hidden w-[213px] border border-[#1D2129] lg:mb-[20px] lg:mt-[8px] lg:block"></div><div class="lg:rounded-0 rounded-[12px] bg-white/30 p-[36px] lg:flex lg:bg-transparent lg:p-0"><div class="float-left h-[118px] w-[118px] lg:float-none lg:h-[112px] lg:w-[112px]"><img src="https://avatars.githubusercontent.com/u/8088864?v=4" class="h-full w-full rounded-[8px] object-cover lg:rounded-[12px]" alt=""/></div><div class="lg:ml-[32px] lg:flex-1 lg:overflow-hidden"><div class="mb-[10px] flex h-[118px] flex-col justify-center pl-[36px] lg:h-auto lg:flex-row lg:items-center lg:justify-between lg:pl-0"><div class="leading-130 montserrat-bold mb-[12px] w-full truncate text-[30px] font-medium text-[#1D2129] lg:mb-0 lg:flex-1 lg:text-[24px]">hankliu62</div><a class="leading-170 ml-0 whitespace-pre-wrap text-[20px] font-normal !text-[#1D2129] !underline hover:!text-[#1D2129] hover:!underline focus:!text-[#1D2129] lg:ml-[5px] lg:text-[14px]" href="https://github.com/hankliu62" target="_blank" rel="noreferrer">TA的个人名片</a></div><div class="leading-170 text-[20px] font-normal text-[#4E5969] lg:text-[14px]">HankLiu前端开发工程师，精通前端，涉猎后端，对前端有着浓厚的兴趣，希望能够在前端这条路上一直走下去。努力去听风的声音，不必在意风的方向。</div></div></div></div></div><div class="ant-divider css-12jzuas ant-divider-horizontal !mt-0 !border-[#bfc3c7]" role="separator"></div><section><div><div class="ant-skeleton ant-skeleton-active css-12jzuas"><div class="ant-skeleton-content"><h3 class="ant-skeleton-title" style="width:38%"></h3><ul class="ant-skeleton-paragraph"><li></li><li></li><li style="width:61%"></li></ul></div></div></div></section></article></div></div></div><div class="w-64 bg-white"><div><div class=""><div class="ant-collapse ant-collapse-icon-position-end question-menus-collapse css-12jzuas"><div class="ant-collapse-item ant-collapse-item-active"><div class="ant-collapse-header" aria-expanded="true" aria-disabled="false" role="button" tabindex="0"><div class="ant-collapse-expand-icon"><span role="img" aria-label="right" class="anticon anticon-right ant-collapse-arrow"><svg viewBox="64 64 896 896" focusable="false" style="-ms-transform:rotate(90deg);transform:rotate(90deg)" data-icon="right" width="1em" height="1em" fill="currentColor" aria-hidden="true"><path d="M765.7 486.8L314.9 134.7A7.97 7.97 0 00302 141v77.3c0 4.9 2.3 9.6 6.1 12.6l360 281.1-360 281.1c-3.9 3-6.1 7.7-6.1 12.6V883c0 6.7 7.7 10.4 12.9 6.3l450.8-352.1a31.96 31.96 0 000-50.4z"></path></svg></span></div><span class="ant-collapse-header-text"><span class="text-base">目录</span></span><div class="ant-collapse-extra"><div class="-mr-2">收起</div></div></div><div class="ant-collapse-content ant-collapse-content-active"><div class="ant-collapse-content-box"><ul class="max-h-[620px] list-none space-y-3 overflow-y-auto text-slate-500 dark:text-slate-400"><li id="## 什么是WebRTC" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base !border-sky-500"><a class="w-full overflow-hidden !text-[#515767] !text-sky-500" href="/frontend/articles/59#%E4%BB%80%E4%B9%88%E6%98%AFwebrtc"><div class="truncate" style="padding-left:16px">什么是WebRTC</div></a></li><li id="## 音视频采集" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E9%9F%B3%E8%A7%86%E9%A2%91%E9%87%87%E9%9B%86"><div class="truncate" style="padding-left:16px">音视频采集</div></a></li><li id="### MediaStreamConstraints" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#mediastreamconstraints"><div class="truncate" style="padding-left:32px">MediaStreamConstraints</div></a></li><li id="#### 视频轨道约束：分辨率" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E8%A7%86%E9%A2%91%E8%BD%A8%E9%81%93%E7%BA%A6%E6%9D%9F%E5%88%86%E8%BE%A8%E7%8E%87"><div class="truncate" style="padding-left:48px">视频轨道约束：分辨率</div></a></li><li id="#### 视频轨道约束：获取移动设备的前置或者后置摄像头" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E8%A7%86%E9%A2%91%E8%BD%A8%E9%81%93%E7%BA%A6%E6%9D%9F%E8%8E%B7%E5%8F%96%E7%A7%BB%E5%8A%A8%E8%AE%BE%E5%A4%87%E7%9A%84%E5%89%8D%E7%BD%AE%E6%88%96%E8%80%85%E5%90%8E%E7%BD%AE%E6%91%84%E5%83%8F%E5%A4%B4"><div class="truncate" style="padding-left:48px">视频轨道约束：获取移动设备的前置或者后置摄像头</div></a></li><li id="### 视频轨道约束：帧率" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E8%A7%86%E9%A2%91%E8%BD%A8%E9%81%93%E7%BA%A6%E6%9D%9F%E5%B8%A7%E7%8E%87"><div class="truncate" style="padding-left:32px">视频轨道约束：帧率</div></a></li><li id="### 常见的音频轨道约束" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E5%B8%B8%E8%A7%81%E7%9A%84%E9%9F%B3%E9%A2%91%E8%BD%A8%E9%81%93%E7%BA%A6%E6%9D%9F"><div class="truncate" style="padding-left:32px">常见的音频轨道约束</div></a></li><li id="### 音视频轨道约束：使用特定的网络摄像头或者麦克风" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E9%9F%B3%E8%A7%86%E9%A2%91%E8%BD%A8%E9%81%93%E7%BA%A6%E6%9D%9F%E4%BD%BF%E7%94%A8%E7%89%B9%E5%AE%9A%E7%9A%84%E7%BD%91%E7%BB%9C%E6%91%84%E5%83%8F%E5%A4%B4%E6%88%96%E8%80%85%E9%BA%A6%E5%85%8B%E9%A3%8E"><div class="truncate" style="padding-left:32px">音视频轨道约束：使用特定的网络摄像头或者麦克风</div></a></li><li id="### 获得当前浏览器支持的约束条件" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E8%8E%B7%E5%BE%97%E5%BD%93%E5%89%8D%E6%B5%8F%E8%A7%88%E5%99%A8%E6%94%AF%E6%8C%81%E7%9A%84%E7%BA%A6%E6%9D%9F%E6%9D%A1%E4%BB%B6"><div class="truncate" style="padding-left:32px">获得当前浏览器支持的约束条件</div></a></li><li id="## 连接管理" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86"><div class="truncate" style="padding-left:16px">连接管理</div></a></li><li id="### RTCSessionDescription（SDP） 会话描述信息对象" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#rtcsessiondescriptionsdp-%E4%BC%9A%E8%AF%9D%E6%8F%8F%E8%BF%B0%E4%BF%A1%E6%81%AF%E5%AF%B9%E8%B1%A1"><div class="truncate" style="padding-left:32px">RTCSessionDescription（SDP） 会话描述信息对象</div></a></li><li id="### NAT 网络地址转换" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#nat-%E7%BD%91%E7%BB%9C%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2"><div class="truncate" style="padding-left:32px">NAT 网络地址转换</div></a></li><li id="### STUN (Session Traversal Utilities for NAT)" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#stun-(session-traversal-utilities-for-nat)"><div class="truncate" style="padding-left:32px">STUN (Session Traversal Utilities for NAT)</div></a></li><li id="### TURN (Traversal Using Relay NAT)" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#turn-(traversal-using-relay-nat)"><div class="truncate" style="padding-left:32px">TURN (Traversal Using Relay NAT)</div></a></li><li id="### ICE技术" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#ice%E6%8A%80%E6%9C%AF"><div class="truncate" style="padding-left:32px">ICE技术</div></a></li><li id="### ICE 候选者 RTCIceCandidate" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#ice-%E5%80%99%E9%80%89%E8%80%85-rtcicecandidate"><div class="truncate" style="padding-left:32px">ICE 候选者 RTCIceCandidate</div></a></li><li id="## 信令服务器" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E4%BF%A1%E4%BB%A4%E6%9C%8D%E5%8A%A1%E5%99%A8"><div class="truncate" style="padding-left:16px">信令服务器</div></a></li><li id="## 端与端之间 P2P 连接" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E7%AB%AF%E4%B8%8E%E7%AB%AF%E4%B9%8B%E9%97%B4-p2p-%E8%BF%9E%E6%8E%A5"><div class="truncate" style="padding-left:16px">端与端之间 P2P 连接</div></a></li><li id="### 1. 连接过程" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#1.-%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B"><div class="truncate" style="padding-left:32px">1. 连接过程</div></a></li><li id="## WebRTC优缺点" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#webrtc%E4%BC%98%E7%BC%BA%E7%82%B9"><div class="truncate" style="padding-left:16px">WebRTC优缺点</div></a></li><li id="### 优点" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E4%BC%98%E7%82%B9"><div class="truncate" style="padding-left:32px">优点</div></a></li><li id="### 缺点" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E7%BC%BA%E7%82%B9"><div class="truncate" style="padding-left:32px">缺点</div></a></li><li id="## 音视频补充知识点" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E9%9F%B3%E8%A7%86%E9%A2%91%E8%A1%A5%E5%85%85%E7%9F%A5%E8%AF%86%E7%82%B9"><div class="truncate" style="padding-left:16px">音视频补充知识点</div></a></li><li id="### 分辨率" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E5%88%86%E8%BE%A8%E7%8E%87"><div class="truncate" style="padding-left:32px">分辨率</div></a></li><li id="### 帧率fps" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E5%B8%A7%E7%8E%87fps"><div class="truncate" style="padding-left:32px">帧率fps</div></a></li><li id="### 码率（比特率）bps" class="border-0 !border-l-2 border-solid border-transparent pr-[16px] text-base"><a class="w-full overflow-hidden !text-[#515767] !hover:text-slate-600 !dark:hover:text-slate-300" href="/frontend/articles/59#%E7%A0%81%E7%8E%87%E6%AF%94%E7%89%B9%E7%8E%87bps"><div class="truncate" style="padding-left:32px">码率（比特率）bps</div></a></li></ul></div></div></div></div></div></div></div></div></div><div style="position:fixed;z-index:9999;top:16px;left:16px;right:16px;bottom:16px;pointer-events:none"></div></main></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"article":{"url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59","repository_url":"https://api.github.com/repos/hankliu62/hankliu62.github.com","labels_url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59/labels{/name}","comments_url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59/comments","events_url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59/events","html_url":"https://github.com/hankliu62/hankliu62.github.com/issues/59","id":1091539489,"node_id":"I_kwDOBiJZIc5BD5Ih","number":59,"title":"浏览器中的WebRTC音视频通讯","user":{"login":"hankliu62","id":8088864,"node_id":"MDQ6VXNlcjgwODg4NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8088864?v=4","gravatar_id":"","url":"https://api.github.com/users/hankliu62","html_url":"https://github.com/hankliu62","followers_url":"https://api.github.com/users/hankliu62/followers","following_url":"https://api.github.com/users/hankliu62/following{/other_user}","gists_url":"https://api.github.com/users/hankliu62/gists{/gist_id}","starred_url":"https://api.github.com/users/hankliu62/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hankliu62/subscriptions","organizations_url":"https://api.github.com/users/hankliu62/orgs","repos_url":"https://api.github.com/users/hankliu62/repos","events_url":"https://api.github.com/users/hankliu62/events{/privacy}","received_events_url":"https://api.github.com/users/hankliu62/received_events","type":"User","site_admin":false},"labels":[{"id":688950687,"node_id":"MDU6TGFiZWw2ODg5NTA2ODc=","url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/labels/blog","name":"blog","color":"1677ff","default":false,"description":"博客文章"}],"state":"open","locked":false,"assignee":{"login":"hankliu62","id":8088864,"node_id":"MDQ6VXNlcjgwODg4NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8088864?v=4","gravatar_id":"","url":"https://api.github.com/users/hankliu62","html_url":"https://github.com/hankliu62","followers_url":"https://api.github.com/users/hankliu62/followers","following_url":"https://api.github.com/users/hankliu62/following{/other_user}","gists_url":"https://api.github.com/users/hankliu62/gists{/gist_id}","starred_url":"https://api.github.com/users/hankliu62/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hankliu62/subscriptions","organizations_url":"https://api.github.com/users/hankliu62/orgs","repos_url":"https://api.github.com/users/hankliu62/repos","events_url":"https://api.github.com/users/hankliu62/events{/privacy}","received_events_url":"https://api.github.com/users/hankliu62/received_events","type":"User","site_admin":false},"assignees":[{"login":"hankliu62","id":8088864,"node_id":"MDQ6VXNlcjgwODg4NjQ=","avatar_url":"https://avatars.githubusercontent.com/u/8088864?v=4","gravatar_id":"","url":"https://api.github.com/users/hankliu62","html_url":"https://github.com/hankliu62","followers_url":"https://api.github.com/users/hankliu62/followers","following_url":"https://api.github.com/users/hankliu62/following{/other_user}","gists_url":"https://api.github.com/users/hankliu62/gists{/gist_id}","starred_url":"https://api.github.com/users/hankliu62/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/hankliu62/subscriptions","organizations_url":"https://api.github.com/users/hankliu62/orgs","repos_url":"https://api.github.com/users/hankliu62/repos","events_url":"https://api.github.com/users/hankliu62/events{/privacy}","received_events_url":"https://api.github.com/users/hankliu62/received_events","type":"User","site_admin":false}],"milestone":null,"comments":0,"created_at":"2021-12-31T11:41:14Z","updated_at":"2021-12-31T11:52:59Z","closed_at":null,"author_association":"OWNER","active_lock_reason":null,"body":"# 浏览器中的WebRTC音视频通讯\r\n\r\n## 什么是WebRTC\r\n\r\nWebRTC: 名称源自网页即时通信（英语：Web Real-Time Communication）的缩写，是一个支持网页浏览器进行实时语音对话或视频对话的API。\r\n\r\nWebRTC 提供了一套标准 API，使 Web 应用可以直接提供实时音视频通信功能。大部分浏览器及操作系统都支持 WebRTC，直接可以在浏览器端发起实时音视频通话。\r\n\r\n对于浏览器来说，这一系列的标准API都已经内置到浏览器中，该技术不需要任何插件或第三方软件，直接使用这些API就能实现一个实时语音对话或视频对话的功能。\r\n\r\nWebRTC API包括媒体捕获，音频和视频编码和解码，传输层和会话管理。\r\n\r\nWebRTC要完成音视频实时通讯需要实现下面四个步骤：音视频采集、STUN/TURN 服务器、信令服务器、端与端之间 P2P 连接，使用 WebRTC 的 API 完成音视频采集，配合信令服务器和 WebRTC 的RTCPeerConnection方法能实现 1V1 通话，简易流程如下图：\r\n\r\n![简易流程图](https://user-images.githubusercontent.com/8088864/147821883-a6e806ae-a593-463b-b5b9-7cb694b559f6.png)\r\n\r\n\r\n## 音视频采集\r\n\r\n音视频采集就是媒体捕获，需要我们访问用户设备的摄像头和麦克风。我们检测到可用设备的类型，获得用户访问这些设备的权限并管理流。\r\n\r\n对于浏览器来说 WebRTC 标准 API 使用`getUserMedia`获取摄像头与话筒对应的媒体流对象`MediaStream`，媒体流可以通过 WebRTC 进行传输，并在多个对等端之间共享。将流对象赋值给视频元素的 srcObject，实现本地播放音视频\r\n\r\n最初，我们可以在navigator.getUserMedia上找到getUserMedia。尽管在某些浏览器上这个操作仍然可行，我们不建议这样做。因为它被标记为已弃用。我们的首选选项是navigator.mediaDevices.getUserMedia。\r\n\r\ngetUserMedia的基本语法为：\r\n``` js\r\nnavigator.mediaDevices.getUserMedia(constraints: MediaStreamConstraints)\r\n```\r\n\r\ngetUserMedia()函数仅接收一个参数，MediaStreamConstraints对象用于指定要请求的轨道类型（音频，视频或二者）以及（可选）每个轨道的任何要求。\r\n\r\n默认情况下，此代码会返回一个promise，该promise会被解析为媒体流。用户可以直接使用它，也可以与async / await一起使用。\r\n\r\n### MediaStreamConstraints\r\n\r\n媒体流的约束值，一般包含下面两个属性，约束项可以具有下面这两个属性中的一个或两个：\r\n\r\n- video: 表示是否需要视频轨道，boolean|MediaTrackConstraints对象\r\n- audio: 表示是否需要音频轨道，boolean|MediaTrackConstraints对象\r\n\r\n#### 视频轨道约束：分辨率\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 640,\r\n    \"height\": 480\r\n  }\r\n}\r\n```\r\n\r\n可以使用宽度和高度属性从网络摄像头请求一定的分辨率。\r\n\r\n浏览器会尽可能的保持这个数据，但是也有可能会返回一个分辨率不一样的流。根据我的经验，这常常是因为摄像头不支持请求的分辨率造成的。也可能是由于在Mac上或者Chrome浏览器其他的标签页上有另一个程序的getUserMedia()覆盖了约束。当然也有可能存在其他原因。\r\n\r\n你可以点击这个链接使用[WebRTC摄像头分辨率查询器](https://webrtchacks.github.io/WebRTC-Camera-Resolution/)来看看自己的浏览器和摄像头都支持什么样的分辨率。\r\n\r\n**关键字**\r\n\r\n如果分辨率对于你来说很重要，而且设备和浏览器不能够保证分辨率的时候，你可以用min，max和exact关键字来帮助你从任何设备中得到最佳的分辨率。这些关键字可以应用到任何MediaTrackConstraint属性中。\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": { \"exact\": 1280 },\r\n    \"height\": { \"exact\": 720 }\r\n  }\r\n}\r\n```\r\n\r\n在上面的例子中，如果不存在支持精确分辨率的摄像头，则返回的promise将会被拒绝并给出`OverconstrainedError`错误，而且不会提醒用户。\r\n\r\n下面展示的这个约束也是请求一个1280×720分辨率的视频，但是它还提到了将320×240作为最小分辨率，因为并不是所有的网络摄像头都可以支持1280×720，所以在某些用例中，设一个值比什么都不设要好：\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": { \"min\": 320, \"max\": 1280 },\r\n    \"height\": { \"min\": 240, \"max\": 720 }\r\n  }\r\n}\r\n```\r\n\r\n那些没有min，max和exact这些关键字描述的值会被视为“ideal”（理想）值，它本身就是一个关键字，但不是强制性的。下面的两个例子完成的是同样一回事：\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 1280,\r\n    \"height\": 720\r\n  }\r\n}\r\n```\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": { \"ideal\": 1280 },\r\n    \"height\": { \"ideal\": 720 }\r\n  }\r\n}\r\n```\r\n\r\n#### 视频轨道约束：获取移动设备的前置或者后置摄像头\r\n\r\n我们可以使用视频轨道约束的facingMode属性。可接受的值有：user（前置摄像头），environment（后置摄像头），left和right。\r\n\r\n下面是如何请求从理想地来自后置摄像头的视频流：\r\n\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 640,\r\n    \"height\": 480,\r\n    \"facingMode\": \"environment\"\r\n  }\r\n}\r\n```\r\n\r\nor\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 640,\r\n    \"height\": 480,\r\n    \"facingMode\": { \"ideal\": \"environment\" }\r\n  }\r\n}\r\n```\r\n\r\n下面是如何请求绝对来自后置摄像头的视频流：\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 640,\r\n    \"height\": 480,\r\n    \"facingMode\": { \"exact\": \"environment\" }\r\n  }\r\n}\r\n```\r\n\r\n### 视频轨道约束：帧率\r\n\r\n**帧率: 每秒显示的帧数，就是1s播放的图片数量(Frames per Second)。**\r\n\r\n因为帧速率不仅对视频质量，还对带宽有着直接影响，所以在某些情况下，比如通过低带宽连接发布视频流的时候，限制帧速率可能是个好主意。我可以使用下面的代码从罗技C925E摄像头获得60fps的视频流：\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"width\": 320,\r\n    \"height\": 240,\r\n    \"frameRate\": { \"ideal\": 60, \"min\": 10 }\r\n  }\r\n}\r\n```\r\n\r\n### 常见的音频轨道约束\r\n\r\n| 字段 | 含义 |\r\n| ---- | ---- |\r\n| sampleRate | 指定一个所需的采样率，不确定它应该被用作编码设置还是作为硬件要求，越高越好（比如CD的采样率就是44000 samples/s或44kHz） |\r\n| sampleSize | 每个采样点大小的位数，越高越好（CD的采样大小为16 bits/sample） |\r\n| volume | 从0（静音）到1（最大音量）取值，被用作每个样本值的乘数 |\r\n| echoCancellation | 是否使用回声消除来尝试去除通过麦克风回传到扬声器的音频 |\r\n| autoGainControl | 是否自动增益修改麦克风的输入音量 |\r\n| noiseSuppression | 是否尝试去除音频信号中的背景噪声 |\r\n| latency | 可接受要求的延迟或延迟范围，以秒为单位 |\r\n| channelCount | 1: 单声道，2: 立体声，从立体声录音切换到单声道录音，能够减少带宽的占用 |\r\n\r\n存在浏览器支持程度的问题，我们可以使用`MediaStreamTrack.getSettings()`检测当前浏览器支持程度\r\n\r\n### 音视频轨道约束：使用特定的网络摄像头或者麦克风\r\n\r\n下面这个约束属性同时适用于音频和视频轨道：deviceId。它指定了被用于捕捉流的设备ID。这个设备ID是唯一的，并且在同一个来源的会话中是相同的。你需要首先使用`MediaDevices.enumerateDevices()`来获取设备id。\r\n\r\n一旦你知道了deviceId之后，你就可以要求指定的摄像头和麦克风了：\r\n\r\n``` json\r\n{\r\n  \"audio\": true,\r\n  \"video\": {\r\n    \"deviceId\": { \"extra\": \"c86ae5d50f136aef03f08658b5c4515e5273e89090982722568ed4b0079c9d5e\" }\r\n  }\r\n}\r\n```\r\n\r\n### 获得当前浏览器支持的约束条件\r\n\r\ngetUserMedia的基本语法为：\r\n``` js\r\nnavigator.mediaDevices.getSupportedConstraints(): object\r\n```\r\n\r\n返回值其成员字段都是客户端（user agent）所支持的约束属性（如帧率，分辨率等）\r\n\r\n\r\n## 连接管理\r\n接下来了解怎么与另一端建立连接，并且传输上面采集到的音视频数据到另一端\r\n\r\n`RTCPeerConnection`是 WebRTC 实现网络连接、媒体管理、数据管理的统一接口。建立 P2P 连接需要用到RTCPeerConnection中的几个重要类：SDP、ICE、STUN/TURN。\r\n\r\n### RTCSessionDescription（SDP） 会话描述信息对象\r\n\r\nSDP 描述的是各端的能力，包括音频编解码器类型、传输协议等。这些信息是建立连接是必须传递的，双方知道视频是否支持音频、编码方式是什么，都能通过 SDP 获得。\r\n\r\n比如进行视频传输，我的编码是 H264 对方只能解 H265，就没法进行通信了。\r\n\r\nSDP 描述分为两部分，分别是会话级别的描述（session level）和媒体级别的描述（media level），其具体的组成可参考 RFC4566[1]，带星号 (*) 的是可选的。常见的内容如下：\r\n\r\n``` text\r\nSession description（会话级别描述）\r\n    v= (protocol version)\r\n    o= (originator and session identifier)\r\n    s= (session name)\r\n    c=* (connection information -- not required if included in all media) One or more Time descriptions (\"t=\" and \"r=\" lines; see below)\r\n    a=* (zero or more session attribute lines) Zero or more Media descriptions\r\nTime description\r\n    t= (time the session is active)\r\n\r\nMedia description（媒体级别描述）, if present\r\n    m= (media name and transport address)\r\n    c=* (connection information -- optional if included at session level)\r\n    a=* (zero or more media attribute lines)\r\n```\r\n\r\nSDP 解析时，每个 SDP Line 都是以 key=... 形式，解析出 key 是 a 后，可能有两种方式，可参考 RFC4566[2]：\r\n```\r\na=\u003cattribute\u003e\r\na=\u003cattribute\u003e:\u003cvalue\u003e\r\n```\r\n\r\n有时候并非冒号 (:) 就一定是 \u003cattribute\u003e:\u003cvalue\u003e，实际上 value 里面也会有冒号，比如：\r\n\r\n```\r\na=fingerprint:sha-256 7C:93:85:40:01:07:91:BE\r\na=extmap:2 urn:ietf:params:rtp-hdrext:toffset\r\na=extmap:3 http://www.webrtc.org/experiments/rtp-hdrext/abs-send-time\r\na=ssrc:2527104241 msid:gLzQPGuagv3xXolwPiiGAULOwOLNItvl8LyS\r\n```\r\n\r\n看一下具体例子：\r\n``` txt\r\nv=0\r\no=alice 2890844526 2890844526 IN IP4 host.anywhere.com\r\ns=\r\nc=IN IP4 host.anywhere.com\r\nt=0 0\r\n//下面的媒体描述，在媒体描述部分包括音频和视频两路媒体\r\nm=audio 49170 RTP/AVP 0\r\na=fmtp:111 minptime=10;useinbandfec=1 //对格式参数的描述\r\na=rtpmap:0 PCMU/8000 //对RTP数据的描述\r\n...\r\n//上面是音频媒体描述，下面是视频媒体描述\r\nm=video 51372 RTP/AVP 31\r\na=rtpmap:31 H261/90000\r\n...\r\nm=video 53000 RTP/AVP 32\r\na=rtpmap:32 MPV/90000\r\n```\r\n\r\n### NAT 网络地址转换\r\n\r\n在真实的网络环境中，NAT（网络地址转换）技术随处可见，它是一种把内部私有网络地址（IP地址）转换为合法网络IP地址的技术。这种通过使用少量的公有IP地址代表较多的私有IP地址的方式，不仅在一定程度上能都有效解决IPv4地址短缺的问题，还能通过隐藏主机IP解决一定的安全问题。但是由于需要连接的个人设备大多数都隐藏在各自的内网当中，导致无法直接获取IP地址，无法直接进行P2P的音视频通信。\r\n\r\n![NAT 网络地址转换](https://user-images.githubusercontent.com/8088864/147821888-a81bc267-89eb-42a2-9d1e-5095ad2deb84.png)\r\n\r\n### STUN (Session Traversal Utilities for NAT)\r\n\r\nSTUN允许位于 NAT（或多重 NAT）后的客户端找出自己的公网地址，查出自己位于哪种类型的 NAT 之后以及 NAT 为某一个本地端口所绑定的公网端端口。\r\n\r\n![STUN](https://user-images.githubusercontent.com/8088864/147821895-2002a983-5ec2-40fa-a226-db978e1b6e2b.png)\r\n\r\n\r\nSTUN是 C/S 模式的协议，由客户端发送 STUN 请求、STUN 服务响应告知由NAT分配给主机的 IP 地址和端口号，也是一种 Request/Response 的协议，默认端口号是 3478。\r\n\r\n想让内网主机知道它的外网 IP，需要在公网上架设一台 STUN server，并向这台服务器发送 Request，服务器就会返回它的公网 IP 了。\r\n\r\n### TURN (Traversal Using Relay NAT)\r\n\r\nTURN 服务器基于TURN（Traversal Using Relays around NAT）协议，用于协助完成STUN服务器无法完成的NAT穿越场景。具体的操作是两端客户端获取TURN服务器的地址，通过TURN服务器进行数据转发，完成间接的P2P直连效果。\r\n\r\nTURN是一种数据传输协议。允许通过 TCP 或 UDP 方式穿透 NAT 或防火墙。TURN 是一个 Client/Server 协议。TURN 的 NAT 穿透方法与 STUN 类似，都是通过取得应用层中的公网地址达到 NAT 穿透\r\n\r\n![TURN](https://user-images.githubusercontent.com/8088864/147821903-e843292c-e2b1-42cb-9ef8-756ee004ae4f.png)\r\n\r\n\r\n### ICE技术\r\n\r\nICE技术基于ICE（Interactive Connectivity Establishment）协议，该协议中一共有三种候选地址（优先级依次下降）：\r\n\r\n- 主机地址（客户端自身自主获取的地址，用于同一局域网进行连接）\r\n- 反射地址（客户端通过STUN服务器获取的地址，即当前设备的外网地址，告知多端即可在外网直连）\r\n- 中继地址（客户端通过TURN服务器获取的地址，后续用于数据中转）\r\n\r\nICE技术的工作流程简单来说就是客户端尽可能获取不同的候选地址，并使用指定的信令通道进行交换，然后根据候选地址的优先级进行连通性测试，最后选择连接效果最优的候选地址建立连接。（ICE技术框架如下图所示）\r\n\r\n![ICE技术](https://user-images.githubusercontent.com/8088864/147821921-c2520f54-295c-482e-a04f-907fc75b293c.png)\r\n\r\n\r\n### ICE 候选者 RTCIceCandidate\r\n\r\nWebRTC 点对点连接最方便的方法是双方 IP 直连，但是在实际的应用中，双方会隔着NAT设备给获取地址造成了麻烦。\r\n\r\nWebRTC 通过ICE框架确定两端建立网络连接的最佳路径，为开发者者屏蔽了复杂的技术细节。\r\n\r\n1. 原理\r\n\r\n两个节点交换 ICE 候选来协商他们自己具体如何连接，一旦两端同意了一个互相兼容的候选，该候选的 SDP 就被用来创建并打开一个连接，通过该连接媒体流就开始运转。\r\n\r\n2. 两个 API\r\n**onicecandidate**：本地代理创建 SDP Offer 并调用 setLocalDescription(offer) 后触发，在 eventHandler 中通过信令服务器将候选信息传递给远端。\r\n\r\n**addIceCandidate**：接收到信令服务器发送过来的候选信息后调用，为本机添加 ICE 代理。\r\n\r\n``` js\r\n// API：pc.onicecandidate = eventHandler\r\npc.onicecandidate = function(event) {\r\n  if (event.candidate) {\r\n    // Send the candidate to the remote peer\r\n  } else {\r\n    // All ICE candidates have been sent\r\n  }\r\n}\r\n\r\n\r\n// API：pc.addIceCandidate\r\npc.addIceCandidate(candidate).then((_) =\u003e {\r\n  // Do stuff when the candidate is successfully passed to the ICE agent\r\n}).catch((e) =\u003e {\r\n  console.log(\"Error: Failure during addIceCandidate()\");\r\n});\r\n```\r\n\r\n## 信令服务器\r\n\r\nWebRTC 的 SDP 和 ICE 信息需要依赖信令服务器进行消息传输与交换、建立 P2P 连接，之后才能进行音视频通话、传输文本信息。如果没有信令服务器，WebRTC 无法进行通信。\r\n\r\n通常使用socket.io实时通信的能力来构建信令服务器。socket.io跨平台、跨终端、跨语言，方便我们在各个端上去实现信令的各个端，去与我们的服务端进行连接。\r\n\r\n这张图就表达了信令服务器在整个通话过程中它起到的作用。\r\n\r\n![信令服务器作用](https://user-images.githubusercontent.com/8088864/147821929-a3de4a43-dd06-4dff-b34c-18c4012b6072.png)\r\n\r\n\r\n用代码看一下如何建立 socket.io 信令服务器\r\n\r\n``` js\r\nconst express = require(\"express\");\r\nconst app = express();\r\nconst https = require(\"https\");\r\nconst { Server } = require(\"socket.io\");\r\nvar fs = require('fs');\r\n//同步读取密钥和签名证书\r\nconst options = {\r\n  key: fs.readFileSync('./keys/server.key'),\r\n  cert: fs.readFileSync('./keys/server.crt')\r\n}\r\n\r\nconst httpServer = https.createServer(options, app);\r\nconst io = new Server(httpServer);\r\n\r\nio.on(\"connection\", (socket) =\u003e {\r\n  console.log(\"a user connected\");\r\n  socket.on(\"message\", (room, data) =\u003e {\r\n    logger.debug(\"message, room: \" + room + \", data, type:\" + data.type);\r\n    socket.to(room).emit(\"message\", room, data);\r\n  })\r\n\r\n  socket.on(\"join\", (room) =\u003e {\r\n    socket.join(room);\r\n  })\r\n});\r\n```\r\n\r\n## 端与端之间 P2P 连接\r\n\r\n### 1. 连接过程\r\n\r\nA 和 B 建立网络连接的过程如图：\r\n\r\n![A 和 B 建立网络连接的过程](https://user-images.githubusercontent.com/8088864/147821938-2f0173b9-c122-453e-b8f3-3e2c334f0b74.png)\r\n\r\n\r\n- A 向 B 发起 WebRTC 呼叫\r\n- 创建 peerConnection 对象，在参数中指定 Turn/Stun 的地址\r\n\r\n``` js\r\nconst pcConfig = {\r\n  iceServers: [\r\n    {\r\n      urls: \"turn:stun.al.learningrtc.cn:3478\",\r\n      credential: \"passwordd\",\r\n      username: \"hankliu\",\r\n    },\r\n    {\r\n      url: \"stun:stun.l.google.com:19302\"\r\n    }\r\n    {\r\n      urls:[\r\n        \"stun:stun.example.com\",\r\n        \"stun:stun-1.example.com\"\r\n      ]\r\n    }\r\n  ],\r\n};\r\n\r\nconst pc = new RTCPeerConnection(pcConfig);\r\n```\r\n\r\n- A 调用createOffer方法创建本地会话描述(SDP offer)，SDP offer 包含有关已附加到 WebRTC 会话，浏览器支持的编解码器和选项的所有MediaStreamTrack信息，以及ICE代理，目的是通过信令信道发送给潜在远程端点，以请求连接或更新现有连接的配置。\r\n\r\n- A 调用setLocalDescription方法将提案设置为本地会话描述，并传递给 ICE 层。之后通过信令服务器将会话描述发送给 B\r\n\r\n``` js\r\n/**\r\n *\r\n * API：pc.createOffer\r\n * 参数：无\r\n * 返回：SDP Offer\r\n *\r\n * API：pc. setLocalDescription\r\n * 参数：offer\r\n * 返回：Promise\u003cnull\u003e\r\n *\r\n */\r\nfunction sendMessage(roomId, data) {\r\n  if (!socket) {\r\n    console.log(\"socket is null\");\r\n  }\r\n  socket.emit(\"__offer__\", roomId, data);\r\n}\r\n\r\nconst offer = await pc.createOffer()\r\n\r\nawait pc.setLocalDescription(new RTCSessionDescription(offer)).catch(handleOfferError);\r\nmessage.log(`传输发起方本地SDP`);\r\n\r\nsendMessage(roomId, offer);\r\n```\r\n\r\n- A 端 pc.setLocalDescription(new RTCSessionDescription(offer))创建后，一个 icecandidate 事件就被发送到RTCPeerConnection，onicecandidate事件会被触发。B 端接收到一个从远端页面通过信令发来的新的 ICE 候选地址信息，本机可以通过调用RTCPeerConnection.addIceCandidate() 来添加一个 ICE 代理。\r\n\r\n``` js\r\n//A端\r\npc.onicecandidate = (event) =\u003e {\r\n  if (!event.candidate) return;\r\n  sendMessage(roomId, {\r\n    type: \"candidate\",\r\n    label: event.candidate.sdpMLineIndex,\r\n    id: event.candidate.sdpMid,\r\n    candidate: event.candidate.candidate,\r\n  });\r\n};\r\n\r\n\r\n//B端\r\nsocket.onmessage = e =\u003e {\r\n  if (e.data.hasOwnProperty(\"type\") \u0026\u0026 e.data.type === \"candidate\") {\r\n    var candidate = new RTCIceCandidate({\r\n      sdpMLineIndex: data.label,\r\n      candidate: data.candidate,\r\n    });\r\n    pc.addIceCandidate(candidate)\r\n      .then(() =\u003e {\r\n        console.log(\"Successed to add ice candidate\");\r\n      })\r\n      .catch((err) =\u003e {\r\n        console.error(err);\r\n      });\r\n  }\r\n}\r\n```\r\n\r\n- A 作为呼叫方获取本地媒体流，调用addStream方法将音视频流流加入RTCPeerConnection对象中传输给另一端，加入时另一端(B)触发onaddstream事件。\r\n\r\n``` js\r\n/**\r\n *\r\n * 媒体流加入媒体轨道\r\n *\r\n * API：stream.getTracks\r\n * 参数：无\r\n * 返回：媒体轨道对象数组\r\n */\r\nconst pc = new RTCPeerConnection();\r\npc.addStream(stream)\r\n\r\nconst remoteVideo = document.querySelector(\"#remote-video\");\r\npc.onaddstream = (e) =\u003e {\r\n  if (e \u0026\u0026 e.stream) {\r\n    message.log(\"收到对方音频/视频流数据...\");\r\n    remoteVideo.srcObject = e.stream;\r\n    // 播放音视频流\r\n    remoteVideo.play();\r\n  }\r\n};\r\n```\r\n\r\n- B 作为呼叫方，从信令服务器收到 A 发过来的会话信息，调用setRemoteDescription方法将提案传递到 ICE 层，调用 addTrack 方法加入 RTCPeerConnection\r\n\r\n- B 调用 createAnswer 方法创建应答，调用setLocalDescription方法应答设置为本地会话并传递给 ICE 层。\r\n\r\n``` js\r\nsocket.onmessage = e =\u003e {\r\n  message.log(\"接收到发送方SDP\");\r\n  await pc.setRemoteDescription(new RTCSessionDescription(e.data));\r\n  message.log(\"创建接收方（应答）SDP\");\r\n  const answer = await pc.createAnswer();\r\n  message.log(`传输接收方（应答）SDP`);\r\n  sendMessage(roomid, answer);\r\n  await pc.setLocalDescription(answer);\r\n}\r\n```\r\n\r\n- AB 都有了自己和对方的 SDP，媒体交换方面达成一致，收集的 ICE 完成连通性检测建立最连接方式，P2P 连接建立，获得对方的音视频媒体流。\r\n\r\n``` js\r\npc.onaddstream = (e) =\u003e {\r\n  if (e \u0026\u0026 e.stream) {\r\n    message.log(\"收到对方音频/视频流数据...\");\r\n    remoteVideo.srcObject = e.stream;\r\n    // 播放音视频流\r\n    remoteVideo.play();\r\n  }\r\n};\r\n```\r\n\r\n\r\n## WebRTC优缺点\r\n目前几乎所有主流浏览器都支持了 WebRTC，越来越多的公司正在使用 WebRTC 并且将其加到自己的应用程序中。在浏览器端，依赖于浏览器获取音视频的能力，以及强大的网页上的渲染能力，就能够为高清的通信体验打下基础。同时，相比移动端来说，屏幕比较大，视窗选择也比较灵活。\r\n\r\n### 优点\r\n\r\n1. 方便。对于用户来说，在WebRTC出现之前想要进行实时通信就需要安装插件和客户端，但是对于很多用户来说，插件的下载、软件的安装和更新这些操作是复杂而且容易出现问题的，现在WebRTC技术内置于浏览器中，用户不需要使用任何插件或者软件就能通过浏览器来实现实时通信。对于开发者来说，在Google将WebRTC开源之前，浏览器之间实现通信的技术是掌握在大企业手中，这项技术的开发是一个很困难的任务，现在开发者使用简单的HTML标签和JavaScript API就能够实现Web音/视频通信的功能。\r\n\r\n2. 免费。虽然WebRTC技术已经较为成熟，其集成了最佳的音/视频引擎，十分先进的codec，但是Google对于这些技术不收取任何费用。\r\n\r\n3. 强大的打洞能力。WebRTC技术包含了使用STUN、ICE、TURN、RTP-over-TCP的关键NAT和防火墙穿透技术，并支持代理。\r\n\r\n### 缺点\r\n\r\n1. 缺乏服务器方案的设计和部署。\r\n\r\n2. 传输质量难以保证。WebRTC的传输设计基于P2P，难以保障传输质量，优化手段也有限，只能做一些端到端的优化，难以应对复杂的互联网环境。比如对跨地区、跨运营商、低带宽、高丢包等场景下的传输质量基本是靠天吃饭，而这恰恰是国内互联网应用的典型场景。\r\n\r\n3. WebRTC比较适合一对一的单聊，虽然功能上可以扩展实现群聊，但是没有针对群聊，特别是超大群聊进行任何优化。\r\n\r\n4. 设备端适配，如回声、录音失败等问题层出不穷。这一点在安卓设备上尤为突出。由于安卓设备厂商众多，每个厂商都会在标准的安卓框架上进行定制化，导致很多可用性问题（访问麦克风失败）和质量问题（如回声、啸叫）。\r\n\r\n5. 对Native开发支持不够。WebRTC顾名思义，主要面向Web应用，虽然也可以用于Native开发，但是由于涉及到的领域知识（音视频采集、处理、编解码、实时传输等）较多，整个框架设计比较复杂，API粒度也比较细，导致连工程项目的编译都不是一件容易的事。\r\n\r\n## 音视频补充知识点\r\n\r\n### 分辨率\r\n\r\n屏幕是由一个个像素点组成的，我们常见的1080p，是指屏幕竖直方向有1080个像素，共有1920列，一共207万像素。2K，2560x1440，共369万像素。\r\n\r\n显示分辨率（屏幕分辨率）是屏幕图像的精密度，是指显示器所能显示的像素有多少。由于屏幕上的点、线和面都是由像素组成的，显示器可显示的像素越多，画面就越精细，同样的屏幕区域内能显示的信息也越多，所以分辨率是个非常重要的性能指标之一。可以把整个图像想象成是一个大型的棋盘，而分辨率的表示方式就是所有经线和纬线交叉点的数目。显示分辨率一定的情况下，显示屏越小图像越清晰，反之，显示屏大小固定时，显示分辨率越高图像越清晰。\r\n\r\n分辨率对视频体积有一定影响，但是不是分辨率越大，视频越清晰，还要看码率。\r\n\r\n\r\n### 帧率fps\r\n\r\n由于人类眼睛的特殊生理结构，如果所看画面之帧率高于24的时候，就会认为是连贯的，此现象称之为视觉暂留。这也就是为什么电影胶片是一格一格拍摄出来，然后快速播放的。\r\n而对游戏，一般来说，第一人称射击游戏比较注重fps的高低，如果fps小于30的话，游戏会显得不连贯。\r\n每秒的帧数(fps)或者说帧率表示图形处理器处理场时每秒钟能够更新的次数。高的帧率可以得到更流畅、更逼真的动画。一般来说30fps就是可以接受的，但是将性能提升至60fps则可以明显提升交互感和逼真感，但是一般来说超过75fps一般就不容易察觉到有明显的流畅度提升了。如果帧率超过屏幕刷新率只会浪费图形处理的能力，因为监视器不能以这么快的速度更新，这样超过刷新率的帧率就浪费掉了。\r\n\r\n\r\n### 码率（比特率）bps\r\n\r\n码率，也叫比特率，帧率是1S播放多少帧，类比一下，比特率就是1s的视频有多少bit。\r\n\r\n这个参数决定了视频是否清晰。\r\n\r\n一个1080P的视频，大小可以为1G，也可以为4G，视频越大，说明1S存放的数据越多，比特率越高，压缩比越小，视频越清晰。\r\n\r\n1080P，长度为100分钟，大小为1GB的视频的比特率是多少？\r\n\r\n```\r\n总时间为\r\n100分钟=100X60S=6000s\r\n总数据量为\r\n1GB=1024MB= 1024X1024KB=1024X1024X1024Byte=1024X1024X1024X8bit=8589934592bit\r\n帧率为 (数据量/时间)\r\n8589934592/6000 = 1.4Mbit/s\r\n```\r\n\r\n帧率和分辨率都可以影响视频体积，但是帧率是主要因素，在工作中如果看到一个很短的视频非常大，很大可能性是因为帧率很大，为了便于网络传输，需要降低帧率。一般来说主流视频平台的帧率在1Mbit/s左右。\r\n\r\n","closed_by":null,"reactions":{"url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59/reactions","total_count":0,"+1":0,"-1":0,"laugh":0,"hooray":0,"confused":0,"heart":0,"rocket":0,"eyes":0},"timeline_url":"https://api.github.com/repos/hankliu62/hankliu62.github.com/issues/59/timeline","performed_via_github_app":null,"state_reason":null},"menus":["## 什么是WebRTC","## 音视频采集","### MediaStreamConstraints","#### 视频轨道约束：分辨率","#### 视频轨道约束：获取移动设备的前置或者后置摄像头","### 视频轨道约束：帧率","### 常见的音频轨道约束","### 音视频轨道约束：使用特定的网络摄像头或者麦克风","### 获得当前浏览器支持的约束条件","## 连接管理","### RTCSessionDescription（SDP） 会话描述信息对象","### NAT 网络地址转换","### STUN (Session Traversal Utilities for NAT)","### TURN (Traversal Using Relay NAT)","### ICE技术","### ICE 候选者 RTCIceCandidate","## 信令服务器","## 端与端之间 P2P 连接","### 1. 连接过程","## WebRTC优缺点","### 优点","### 缺点","## 音视频补充知识点","### 分辨率","### 帧率fps","### 码率（比特率）bps"]},"__N_SSG":true},"page":"/articles/[id]","query":{"id":"59"},"buildId":"0KgTm-4rBEt_lvVIgTS_U","assetPrefix":"/frontend","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>